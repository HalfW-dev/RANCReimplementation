{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all the cool stuff so that this thing would run (yeah you gotta install the legacy version cause the folks at Arizona won't bother updating everything to Tensorflow 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tealayer2 import Tea, AdditivePooling\n",
    "from tensorflow.keras.layers import Flatten, Activation, Input, Lambda, concatenate\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "from rancutils.teaconversion import create_cores, create_packets, Packet\n",
    "from rancutils.output_bus import OutputBus\n",
    "from rancutils.serialization import save as sim_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare your dataset. Note: X refers to the parameters used for prediction (in this case the pixel values), and Y refers to the actual prediction (in this case numbers from 0 to 9 inferred from the images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "            \n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your input (2D array of the coordinates of the pixel of an image, with only 1 value - greyscale value) and flatten them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greyscale images are of shape (28,28,1)\n",
    "inputs = Input(shape=(28,28,1))\n",
    "\n",
    "# Flatten the inputs so that inputs map as: flatten_input[0] -> axon[0], ..., flatten_input[255] -> axon[255]\n",
    "flattened_inputs = Flatten()(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the fun part. You get to define the topology of your RANC Network. The code below would create a network with the following attributes:\n",
    "- The first layer of the network consists of 4 cores. Each core takes in 256 inputs from flattened_inputs. You may notice that the inputs taken by each core overlap with each other. This overlap is intentional and focused on the center of the image (where most of the bright pixels of the image are situated).\n",
    "- Each core of the first layer spits out 64 outputs (or \"neurons\" in RANC lingo). These \"neurons\" are taken in by the second layer of the network. This second layer only has 250 outputs, which are split into 10 groups of 25 to predict the 10 classes from 0 to 9.\n",
    "- How do we split the output of the second layer? By using the utility class AdditivePooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate each core.\n",
    "# We are taking a 16x16 square of the input image and striding it by 12. this gives us 4 cores with 0 padding encumpassing the entire image.\n",
    "core0 = Lambda(lambda x : x[:, :256])(flattened_inputs)\n",
    "core1 = Lambda(lambda x : x[:, 176:432])(flattened_inputs)\n",
    "core2 = Lambda(lambda x : x[:, 352:608])(flattened_inputs)\n",
    "core3 = Lambda(lambda x : x[:, 528:])(flattened_inputs)\n",
    "\n",
    "# Use the image distributions as corresponding inputs into our Tea Layer.\n",
    "core0 = Tea(units=64, name='tea_1_1')(core0)\n",
    "core1 = Tea(units=64, name='tea_1_2')(core1)\n",
    "core2 = Tea(units=64, name='tea_1_3')(core2)\n",
    "core3 = Tea(units=64, name='tea_1_4')(core3)\n",
    "\n",
    "# The classification is the concatenation of these 4 core's outputs.\n",
    "# We'll call the classification core our 'network'\n",
    "network = concatenate([core0, core1, core2, core3])\n",
    "\n",
    "network = Tea(units=250, name='tea_2')(network)\n",
    "\n",
    "network = AdditivePooling(10)(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the preparations done, we can now start to train the network and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Activation('softmax')(network)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the score (or more accurately, the loss and the accuracy of the model). At the time of writing this, the accuracy should fall somewhere between 92-95% (which kinda sucks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Loss: \", score[0])\n",
    "print(\"Test Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the crux - converting the inputs to input spikes to be passed into the C++ simulator and the outputs to output spikes to be used for cross-validation between the Tensorflow environment, C++ simulator, and FPGA implementation.\n",
    "\n",
    "In case you don't know or wonder why, the point of RANC is to make advancement in neurophormic computing - to ultilize SNN and implement them effectively on dedicated hardware.\n",
    "\n",
    "RANC is not created to be \"yet another AI model\" that is \"0.01% percent more accurate than that ABCXYZ model published in a paper last month\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_flat = X_test.reshape((10000, 784))\n",
    "partitioned_packets = []\n",
    "\n",
    "# Use absolute/hard reset by specifying neuron_reset_type=0\n",
    "cores_sim = create_cores(model, 2, neuron_reset_type=0)\n",
    "num_test_samples = 100\n",
    "# Partition the packets into groups as they will be fed into each of the input cores\n",
    "partitioned_packets.append(x_test_flat[:num_test_samples, :256])\n",
    "partitioned_packets.append(x_test_flat[:num_test_samples, 176:432])\n",
    "partitioned_packets.append(x_test_flat[:num_test_samples, 352:608])\n",
    "partitioned_packets.append(x_test_flat[:num_test_samples, 528:])\n",
    "packets_sim = create_packets(partitioned_packets)\n",
    "output_bus_sim = OutputBus((0, 2), num_outputs=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the input.json file for the C++ simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file can then be used as an input json to the RANC Simulator through the \"input file\" argument.\n",
    "sim_save(\"./toy/mnist_config.json\", cores_sim, packets_sim, output_bus_sim, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also save the prediction result of the Tensorflow environment, along with the correct result for later cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test[:num_test_samples,:])\n",
    "print(type(predict))\n",
    "idx = []\n",
    "for i in predict:\n",
    "  idx.append(np.argmax(i))\n",
    "test_predictions = to_categorical(idx)\n",
    "\n",
    "# Additionally, output the tensorflow predictions and correct labels for later cross validation\n",
    "np.savetxt(\"./toy/mnist_tf_preds.txt\", test_predictions, delimiter=',', fmt='%i')\n",
    "np.savetxt(\"./toy/mnist_correct_preds.txt\", y_test[0:99], delimiter=',', fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code saves the result in the form of one-hot. We can also save the result in spike form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = model.layers[-3].name\n",
    "cool_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "spike_output = cool_model.predict(X_test[:num_test_samples,:])\n",
    "#print(intermediate_output)\n",
    "\n",
    "np.savetxt('./toy/spike_output.txt', spike_output, fmt='%i')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
